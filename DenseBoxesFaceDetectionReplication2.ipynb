{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev2 toc-item\"><a href=\"#Plan\" data-toc-modified-id=\"Plan-01\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Plan</a></div><div class=\"lev2 toc-item\"><a href=\"#Classes\" data-toc-modified-id=\"Classes-02\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Classes</a></div><div class=\"lev2 toc-item\"><a href=\"#Tests\" data-toc-modified-id=\"Tests-03\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Tests</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "* Sit for 3 hours and finish it. Rest will happen automatically. \n",
    "* Function call flow:\n",
    "* x -> x_down -> y_loc, y_class -> pred_loc, pred_class -> loss_class, loss_reg -> loss\n",
    "* This completes the feedback loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "The following classes/methods exist in the dataset\n",
    "* downsample\n",
    "* encode\n",
    "* Network\n",
    "* Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T11:30:35.519257Z",
     "start_time": "2017-12-08T11:30:28.011010Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from network import VGGNet\n",
    "\n",
    "\n",
    "def encode_y(x_down, labels_down):\n",
    "    \"\"\"\n",
    "    x_downsampled tensor -> y_tensor: Numpy\n",
    "    \n",
    "    Args:\n",
    "        x_down (b, 3, 60, 60): Downsampled list of images\n",
    "        labels_down (b, v, 2): List of lists of lists (downsampled boxes)\n",
    "        \n",
    "    Returns:\n",
    "        y_class (b, 1, 60, 60): Tensor containing mask for each image. Calculated within encode\n",
    "        y_loc (b, 4, 60, 60):\n",
    "    \"\"\"\n",
    "    \n",
    "    y_class = np.zeros((x_down.shape[0], x_down.shape[2], x_down.shape[3]))\n",
    "    y_loc = np.zeros((x_down.shape[0], 4, x_down.shape[2], x_down.shape[3]))\n",
    "    \n",
    "    y_class[x_down[:,0,:,:]>0] = 1 # Can also choose a smaller neighbourhood here\n",
    "    pos_inds = np.argwhere(y_class) # y_class is also the positive examples mask\n",
    "    \n",
    "    for b, y, x in pos_inds:\n",
    "        y_loc[b, :, y, x] = match_boxes(x, y, labels_down[b])\n",
    "        \n",
    "    y_class = y_class.reshape(x_down.shape[0], 1, x_down.shape[2], x_down.shape[3])\n",
    "    \n",
    "    return y_class, y_loc\n",
    "\n",
    "def match_boxes(x, y, boxes):\n",
    "    \"\"\" Numpy\n",
    "    Matches a point (x,y) to a bunch of boxes. Returns offset of the box with the nearest centre.\n",
    "    \n",
    "    Args:\n",
    "        x (scalar): X coordinate of point being matched\n",
    "        y (scalar): Y coordinate of point being matched\n",
    "        boxes: List of list of downsampled boxes being matched, in (tx, ty, bx, by) notation\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dist = 10**5 # Store the smallest disance to a large no initially, can glitch if dist greater than this\n",
    "    \n",
    "    for box in boxes:\n",
    "        cx = (box[0] + box[2])/2\n",
    "        cy = (box[1] + box[3])/2\n",
    "        \n",
    "        box_dist = (cx - x)**2 + (cy - y)**2\n",
    "        \n",
    "        if box_dist < dist:\n",
    "            offset = np.array([box[0] - x, box[1] - y, box[2] - x, box[3] - y])\n",
    "            dist = box_dist\n",
    "            \n",
    "    # Should not glitch because matching is only done for positive indices\n",
    "    return offset\n",
    "    \n",
    "\n",
    "def downsample(x, labels):\n",
    "    \"\"\"\n",
    "    x -> x/4\n",
    "    \n",
    "    Args:\n",
    "        x (b, 3, 240, 240): Batch of 3 channel 240 x 240 images\n",
    "        labels (b, v, 4): List of list of boxes\n",
    "\n",
    "    Returns:\n",
    "        x_down (b, 3, 60, 60): Batch of 3 channel 60x60 images\n",
    "        labels_down (b, v, 4): List of list of downsampled boxes\n",
    "    \"\"\"\n",
    "    # Resize batch by two max pools\n",
    "    x_down = F.max_pooling_2d(F.max_pooling_2d(x, 2, stride=2 ), 2, stride=2 ) # Is this correct? Should we use bilinear interpolation instead?\n",
    "    labels_down = labels/4.0\n",
    "    \n",
    "    return x_down.data, labels_down\n",
    "\n",
    "def loss(pred_class, pred_loc, gt_class, gt_loc, lambd=0.4):\n",
    "    \"\"\"\n",
    "    Calculates weighted sum of classification and regression loss. Calls the classification loss and regression loss functions separately.\n",
    "    \n",
    "    Args:\n",
    "        pred_class (b, 1, 60, 60): Network confidence probs for images\n",
    "        pred_loc (b, 4, 60, 60): Network offsets for each location\n",
    "        gt_class (b, 1, 60, 60): Gt class scores from encode\n",
    "        gt_loc (b, 4, 60, 60): Gt regression offsets from encode\n",
    "        lambd (scalar): WEighting factor comparison regression loss to \n",
    "        \n",
    "    Returns:\n",
    "        loss: Scalar value of \n",
    "    \"\"\"\n",
    "    return classification_loss(pred_class, gt_class) + lambd * regression_loss(pred_loc, gt_loc, gt_class)\n",
    "\n",
    "def classification_loss(pred_class, gt_class, debug=False):\n",
    "    \"\"\"\n",
    "    Classification loss from mean squared diff between probabilities. Should probably use cross entropy instead but usng this now for simplicity.\n",
    "    \n",
    "    Also does hard negative mining. so requires generation of a selction mask of positives and most overconfident negatives.\n",
    "    \n",
    "    Args:\n",
    "        pred_class (b, 1, 60, 60): Network confidence probs\n",
    "        gt_class (b, 1, 60, 60): Binary gt confidence probs\n",
    "        \n",
    "    Returns:\n",
    "        class_loss: Scalar\n",
    "    \"\"\"\n",
    "    abs_loss = (pred_class - gt_class) ** 2\n",
    "    mask = selection_mask(abs_loss, gt_class)\n",
    "    selected_loss = abs_loss * mask\n",
    "    \n",
    "    if debug:\n",
    "        return selected_loss/pred_class.shape[0]\n",
    "    else:\n",
    "        return selected_loss.sum()/pred_class.shape[0]\n",
    "\n",
    "def regression_loss(pred_loc, gt_loc, gt_class, debug=False):\n",
    "    \"\"\"\n",
    "    Regression loss from vanilla mean squared diff between shifts.\n",
    "    \n",
    "    Args:\n",
    "        pred_loc (b, 4, 60, 60): Network offsets for top left and bottom right of box. Should \n",
    "        gt_loc (b, 4, 60, 60): Ground truth offsets for top left and bottom right of box.  \n",
    "        gt_class (b, 1, 60, 60): Offsets for positive examples\n",
    "        \n",
    "    Returns:\n",
    "        reg_loss: Scalar\n",
    "    \"\"\"\n",
    "    abs_loss = ((pred_loc - gt_loc) ** 2).sum(axis=1) # Check dims in test\n",
    "    selected_loss = abs_loss * gt_class\n",
    "    \n",
    "    if debug:\n",
    "        return selected_loss/pred_loc.shape[0]\n",
    "    else:\n",
    "        return selected_loss.sum()/pred_loc.shape[0]\n",
    "\n",
    "def selection_mask(abs_loss, gt_class):\n",
    "    \"\"\" Is there a simpler way of doing this?\n",
    "    Returns a binary mask from absolute mean square classification loss and the ground truth mask\n",
    "    \n",
    "    Args:\n",
    "        abs_loss (b, 1, 60, 60): Absolute probability loss value over each pixel\n",
    "        gt_class (b, 1, 60, 60): Binary gt probs to set the positive pixels to one\n",
    "        \n",
    "    Returns;\n",
    "        select_mask (b, 1, 60, 60): Selection mask for poth positive and negative pixels0\n",
    "    \"\"\"\n",
    "    yinv = 1 - gt_class\n",
    "    \n",
    "    loss_neg = yinv*abs_loss\n",
    "\n",
    "    select_mask = np.zeros(gt_class.shape)\n",
    "\n",
    "    for num,i in enumerate(loss_neg):\n",
    "        # Getting the sorted indices loss in a flat array\n",
    "        indices = np.argsort(i,axis=None )\n",
    "\n",
    "        # Reshaping the flat indices to matrix indices\n",
    "        matrix_indices = np.unravel_index(indices,(abs_loss.shape[2], abs_loss.shape[3]))\n",
    "        matrix_indices_flipped = np.fliplr(matrix_indices)\n",
    "\n",
    "        num_positives = int(np.sum(gt_class[num,:,:]))\n",
    "        \n",
    "        # Taking the top num_positives indices only\n",
    "        matrix_indices_sorted = matrix_indices_flipped[:,0:num_positives]\n",
    "\n",
    "        select_mask[num,0,matrix_indices_sorted[0],matrix_indices_sorted[1]] = 1 # Setting the top negative indices to one\n",
    "        select_mask[num,0,:,:] = select_mask[num,0,:,:] + gt_class[num,0,:,:] # Setting all positive indices to one\n",
    "        \n",
    "    return select_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "Writing tests for all of these methods. Checking all of them should be sufficient for this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T11:30:44.287898Z",
     "start_time": "2017-12-08T11:30:35.522723Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 0 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=0 errors=0 failures=0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "from unittest import TestSuite\n",
    "from dataset import SquaresDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import chainer.functions as F\n",
    "\n",
    "class TestCode(unittest.TestCase):\n",
    "    \n",
    "    def test_dataset(self):\n",
    "        \"\"\" TESTED: Test that datast works \"\"\"\n",
    "        # Basic plotting\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Dataset generation example', fontsize=20)\n",
    "        \n",
    "        # Generate and visualize the dataset squares\n",
    "        db = SquaresDataset()\n",
    "        imgs, labels = db.generate_batch(n=2, h=20, w=20, img_h=60, img_w=60)\n",
    "        db.visualize_batch(imgs, labels)\n",
    "    \n",
    "    def test_encode_y(self):\n",
    "        \"\"\" TESTED: Manually worked out example with batch size of two. Trivial category. \"\"\"\n",
    "        # Encoded boxes in a couple of boxes should look like the distance transform\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Encode y example', fontsize=20)\n",
    "        \n",
    "        # Let's try with random values first\n",
    "        db = SquaresDataset()\n",
    "        imgs, labels = db.generate_batch(n=2, h=20, w=20, img_h=60, img_w=60)\n",
    "        gt_class, gt_loc = encode_y(imgs, labels)\n",
    "\n",
    "        # Plot the encoded values\n",
    "        plt.imshow(gt_loc[0,2,:,:])\n",
    "        plt.show()\n",
    "        \n",
    "    def test_downsample(self):\n",
    "        \"\"\" LOGIC: Test that shape matches. \"\"\"\n",
    "        # Basic plotting\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Downsampling visual test', fontsize=20)\n",
    "        \n",
    "        # Let's generate some boxes\n",
    "        db = SquaresDataset()\n",
    "        imgs, labels = db.generate_batch(n=2, h=80, w=80, img_h=240, img_w=240)\n",
    "        db.visualize_batch(imgs, labels)\n",
    "        \n",
    "        # Check that boxes redrawn after downsampling look identical to original ones\n",
    "        imgs_down, labels_down = downsample(imgs, labels)\n",
    "        db.visualize_batch(imgs_down, labels_down)\n",
    "    \n",
    "    def test_predict(self):\n",
    "        \"\"\" LOGIC: What does this method do? \"\"\"\n",
    "        # Visualizing should also be fine\n",
    "        \n",
    "        # Do not implement for now. Only get the regression loss to work.\n",
    "        pass\n",
    "    \n",
    "    def test_network(self):\n",
    "        \"\"\" LOGIC: Test that the shape is correct? \"\"\"\n",
    "        db = SquaresDataset()\n",
    "        imgs, labels = db.generate_batch(n=2, h=20, w=20, img_h=240, img_w=240)\n",
    "        \n",
    "        vgg = VGGNet()\n",
    "        \n",
    "        pred_loc, pred_class= vgg(imgs)\n",
    "        print(' pred_loc shape :', pred_loc.shape)\n",
    "        print(' pred_class shape :', pred_class.shape)\n",
    "        \n",
    "        # Need to add more tests here. Just checking for shape is not sufficient.\n",
    "    \n",
    "    def test_loss(self):\n",
    "        \"\"\" LOGIC: Calculate sample loss for the network. Trivial category. \"\"\"\n",
    "        print(loss(pred_class, pred_loc, gt_class, gt_loc, lambd=0.4))\n",
    "        \n",
    "        # Not really needed but let's still add a debug flag and check that this works\n",
    "        pass\n",
    "    \n",
    "    def test_reg_loss(self):\n",
    "        \"\"\" LOGIC: Calculate regression loss for the network with batch size of two. Trivial category. \"\"\"\n",
    "        # Shift by two pixels and check?\n",
    "        # Basic plotting\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Regression loss example', fontsize=20)\n",
    "        \n",
    "        # Should we show the regression loss hm here?\n",
    "        db = SquaresDataset()\n",
    "        imgs, labels = db.generate_batch(n=2, h=20, w=20, img_h=240, img_w=240)\n",
    "        x_down, labels_down = downsample(imgs, labels)\n",
    "        \n",
    "        # Loss calculation\n",
    "        pred_class, pred_loc = vgg(imgs)\n",
    "        gt_class, gt_loc = encode_y(imgs, labels)\n",
    "        reg_loss = regression_loss(pred_loc, gt_loc, gt_class)\n",
    "        \n",
    "        # Plot and print the final regression loss\n",
    "    \n",
    "    def test_class_loss(self):\n",
    "        \"\"\" LOGIC: Calculate classification loss for the network with batch size of two. Trivial category. \"\"\"\n",
    "        # Should we show the classification loss heatmap here?\n",
    "        # Shift by two pixels and check?\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Classification loss example', fontsize=20)\n",
    "        \n",
    "        # Generate data\n",
    "        db = SquaresDataset()\n",
    "        imgs, labels = db.generate_batch(n=2, h=20, w=20, img_h=240, img_w=240)\n",
    "        imgs_down, labels_down = downsample(imgs, labels)\n",
    "        \n",
    "        # Loss calculation\n",
    "        vgg = VGGNet()\n",
    "        pred_class, pred_loc = vgg(imgs)\n",
    "        gt_class, gt_loc = encode_y(imgs_down, labels_down)\n",
    "        \n",
    "        class_loss = classification_loss(pred_class, gt_class)\n",
    "        \n",
    "        # Plot and print the final loss\n",
    "        pass\n",
    "    \n",
    "    def test_classifier_learning_capacity(self):\n",
    "        \"\"\" Is the network able to do any auxillary learning task properly \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def test_convergence(self):\n",
    "        \"\"\" Check that for the one and two squares datasets, the network loss convergence. Plot the loss and show that it converges. \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def test_select_mask(self):\n",
    "        \"\"\" For controlled inputs, check what the mask looks like. Does it look sensible? \"\"\"\n",
    "        # Plotting stuff\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Selection mask visualization', fontsize=20)\n",
    "        \n",
    "        # Generate data\n",
    "        db = SquaresDataset()\n",
    "        imgs, labels = db.generate_batch(n=2, h=20, w=20, img_h=240, img_w=240)\n",
    "        imgs_down, labels_down = downsample(imgs, labels)\n",
    "        \n",
    "        # Loss calculation\n",
    "        #vgg = VGGNet()\n",
    "        gt_class, gt_loc = encode_y(imgs_down, labels_down)\n",
    "        pred_class, pred_loc = gt_class, gt_loc\n",
    "        \n",
    "        \n",
    "        # Absolute loss calculation\n",
    "        abs_loss = (pred_class - gt_class) ** 2\n",
    "        mask = selection_mask(abs_loss, gt_class)\n",
    "        \n",
    "        # Display the selection mask\n",
    "        plt.imshow(mask[0,0,:,:])\n",
    "        plt.show()\n",
    "    \n",
    "ts = TestSuite()\n",
    "#ts.ad\n",
    "#ts.addTests([TestCode('test_select_mask')])\n",
    "#ts.addTests([TestCode('test_encode_y'),\n",
    "#             TestCode('test_downsample'),TestCode('test_network'),\n",
    "#             TestCode('test_reg_loss'),TestCode('test_select_mask')  ])\n",
    "\n",
    "unittest.TextTestRunner().run(ts)\n",
    "#alltests = unittest.TestSuite([fast, slow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhgxfasjwpYYMX2rI8KWGDF9qyPClhv4P5AnYl8B9j70AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f290ae09c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "db = SquaresDataset()\n",
    "imgs, labels = db.generate_batch(n=2, h=20, w=20, img_h=240, img_w=240)\n",
    "imgs_down, labels_down = downsample(imgs, labels)\n",
    "\n",
    "# Loss calculation\n",
    "#vgg = VGGNet()\n",
    "gt_class, gt_loc = encode_y(imgs_down, labels_down)\n",
    "pred_class, pred_loc = gt_class.copy()+2, gt_loc.copy()+3\n",
    "\n",
    "# Absolute loss calculation\n",
    "abs_loss = (pred_class - gt_class) ** 2\n",
    "abs_loss[]\n",
    "#mask = selection_mask(abs_loss, gt_class)\n",
    "\n",
    "plt.imshow(abs_loss[0,0,:,:],cmap =)\n",
    "plt.show()\n",
    "# Display the selection mask\n",
    "# plt.imshow(mask[0,0,:,:])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.  4.  4. ...,  4.  4.  4.]\n",
      " [ 4.  4.  4. ...,  4.  4.  4.]\n",
      " [ 4.  4.  4. ...,  4.  4.  4.]\n",
      " ..., \n",
      " [ 4.  4.  4. ...,  4.  4.  4.]\n",
      " [ 4.  4.  4. ...,  4.  4.  4.]\n",
      " [ 4.  4.  4. ...,  4.  4.  4.]]\n"
     ]
    }
   ],
   "source": [
    "print(abs_loss[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAC9RJREFUeJzt3V/I3YV9x/H3Z0lMWlvRtDYEI4vDsOLFjBCsRS9anSVz\npXohopSSi0BuOrCs0MUNBoVd1JvaXuwmTGkuuqprKwlS1mapZQxG9LFqG02tqViaEM3+KO0GyxL7\n3cXzS3kWkjwnz3P+PPJ9v+Bwfr/f+Z38vuSc9/M75zwHnlQVknr5vVkPIGn6DF9qyPClhgxfasjw\npYYMX2rI8KWGDF9qaFnhJ9me5NUkR5PsHtdQkiYrS/3mXpJVwM+BO4FjwHPAA1X1yoXuc1nW1jou\nX9LxJC3uf/hv/rdOZbH9Vi/jGDcDR6vqdYAkjwN3AxcMfx2X87HcsYxDSrqYQ3VwpP2W81L/GuBX\nC9aPDdv+nyS7kswlmTvNqWUcTtK4TPzDvaraU1XbqmrbGtZO+nCSRrCc8I8D1y5Y3zRsk7TCLSf8\n54AtSa5LchlwP7B/PGNJmqQlf7hXVWeS/BnwfWAV8FhVvTy2ySRNzHI+1aeqvgd8b0yzSJoSv7kn\nNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81\nZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzW0aPhJHktyMsnhBdvWJzmQ5LXh+qrJ\njilpnEY5438D2H7Ott3AwaraAhwc1iW9RywaflX9M/Cf52y+G9g7LO8F7hnzXJImaKl/JntDVZ0Y\nlt8ENlxoxyS7gF0A63j/Eg8naZyW/eFeVRVQF7l9T1Vtq6pta1i73MNJGoOlhv9Wko0Aw/XJ8Y0k\nadKWGv5+YMewvAPYN55xJE3DKL/O+xbwr8AfJjmWZCfwFeDOJK8BfzysS3qPWPTDvap64AI33THm\nWSRNid/ckxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5ca\nMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caGuWPZl6b5JkkryR5OcmD\nw/b1SQ4keW24vmry40oah1HO+GeAL1bVDcAtwOeT3ADsBg5W1Rbg4LAu6T1g0fCr6kRV/XhY/g1w\nBLgGuBvYO+y2F7hnUkNKGq9Leo+fZDNwE3AI2FBVJ4ab3gQ2jHUySRMzcvhJPgB8B/hCVf164W1V\nVUBd4H67kswlmTvNqWUNK2k8Rgo/yRrmo/9mVX132PxWko3D7RuBk+e7b1XtqaptVbVtDWvHMbOk\nZRrlU/0AjwJHquqrC27aD+wYlncA+8Y/nqRJWD3CPrcCnwN+muTFYdtfAl8BnkyyE/glcN9kRpQ0\nbouGX1X/AuQCN98x3nEkTYPf3JMaMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoy\nfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGhrl\nr+WuS/JskpeSvJzky8P265IcSnI0yRNJLpv8uJLGYZQz/ing9qq6EdgKbE9yC/Aw8EhVXQ+8Deyc\n3JiSxmnR8Gvefw2ra4ZLAbcD3x627wXumciEksZupPf4SVYleRE4CRwAfgG8U1Vnhl2OAddMZkRJ\n4zZS+FX1blVtBTYBNwMfHfUASXYlmUsyd5pTSxxT0jhd0qf6VfUO8AzwceDKJKuHmzYBxy9wnz1V\nta2qtq1h7bKGlTQeo3yqf3WSK4fl9wF3AkeY/wFw77DbDmDfpIaUNF6rF9+FjcDeJKuY/0HxZFU9\nneQV4PEkfwO8ADw6wTkljdGi4VfVT4CbzrP9debf70t6j/Gbe1JDhi81ZPhSQ4YvNWT4UkOGLzVk\n+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4\nUkOGLzVk+FJDhi81ZPhSQyOHn2RVkheSPD2sX5fkUJKjSZ5IctnkxpQ0Tpdyxn+Q+T+PfdbDwCNV\ndT3wNrBznINJmpyRwk+yCfhT4O+G9QC3A98edtkL3DOJASWN36hn/K8BXwJ+O6x/CHinqs4M68eA\na8Y8m6QJWTT8JJ8GTlbV80s5QJJdSeaSzJ3m1FL+CUljtnqEfW4FPpPkLmAdcAXwdeDKJKuHs/4m\n4Pj57lxVe4A9AFdkfY1laknLsugZv6oeqqpNVbUZuB/4YVV9FngGuHfYbQewb2JTShqr5fwe/y+A\nP09ylPn3/I+OZyRJkzbKS/3fqaofAT8all8Hbh7/SJImzW/uSQ0ZvtSQ4UsNGb7UkOFLDRm+1JDh\nSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFL\nDRm+1JDhSw0ZvtSQ4UsNGb7U0Eh/NDPJG8BvgHeBM1W1Lcl64AlgM/AGcF9VvT2ZMSWN06Wc8T9Z\nVVuratuwvhs4WFVbgIPDuqT3gOW81L8b2Dss7wXuWf44kqZh1PAL+EGS55PsGrZtqKoTw/KbwIbz\n3THJriRzSeZOc2qZ40oah5He4wO3VdXxJB8BDiT52cIbq6qS1PnuWFV7gD0AV2T9efeRNF0jnfGr\n6vhwfRJ4CrgZeCvJRoDh+uSkhpQ0XouGn+TyJB88uwx8CjgM7Ad2DLvtAPZNakhJ4zXKS/0NwFNJ\nzu7/91X1j0meA55MshP4JXDf5MaUNE6Lhl9VrwM3nmf7fwB3TGIoSZPlN/ekhgxfasjwpYYMX2rI\n8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjw\npYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGUlXTO1jyb8z/Se0PA/8+tQMvznkubqXNAytv\nppUyz+9X1dWL7TTV8H930GSuqrZN/cAX4DwXt9LmgZU300qbZzG+1JcaMnypoVmFv2dGx70Q57m4\nlTYPrLyZVto8FzWT9/iSZsuX+lJDUw0/yfYkryY5mmT3NI+9YIbHkpxMcnjBtvVJDiR5bbi+aorz\nXJvkmSSvJHk5yYOznCnJuiTPJnlpmOfLw/brkhwaHrsnklw2jXkWzLUqyQtJnp71PEneSPLTJC8m\nmRu2zew5tBRTCz/JKuBvgT8BbgAeSHLDtI6/wDeA7eds2w0crKotwMFhfVrOAF+sqhuAW4DPD/8v\ns5rpFHB7Vd0IbAW2J7kFeBh4pKquB94Gdk5pnrMeBI4sWJ/1PJ+sqq0LfoU3y+fQpauqqVyAjwPf\nX7D+EPDQtI5/ziybgcML1l8FNg7LG4FXZzHXcPx9wJ0rYSbg/cCPgY8x/+WU1ed7LKcwxybmY7od\neBrIjOd5A/jwOdtm/nhdymWaL/WvAX61YP3YsG0l2FBVJ4blN4ENsxgiyWbgJuDQLGcaXla/CJwE\nDgC/AN6pqjPDLtN+7L4GfAn47bD+oRnPU8APkjyfZNewbUU8h0a1etYDrDRVVUmm/quOJB8AvgN8\noap+nWRmM1XVu8DWJFcCTwEfndaxz5Xk08DJqno+ySdmNcc5bquq40k+AhxI8rOFN87qOXQppnnG\nPw5cu2B907BtJXgryUaA4frkNA+eZA3z0X+zqr67EmYCqKp3gGeYfyl9ZZKzJ4ppPna3Ap9J8gbw\nOPMv978+w3moquPD9UnmfzDezAp4vC7FNMN/DtgyfBp7GXA/sH+Kx7+Y/cCOYXkH8++zpyLzp/ZH\ngSNV9dVZz5Tk6uFMT5L3Mf95wxHmfwDcO+15quqhqtpUVZuZf878sKo+O6t5klye5INnl4FPAYeZ\n4XNoSab5gQJwF/Bz5t8z/tUsPtQAvgWcAE4z/95wJ/PvGQ8CrwH/BKyf4jy3Mf+e8SfAi8PlrlnN\nBPwR8MIwz2Hgr4ftfwA8CxwF/gFYO4PH7hPA07OcZzjuS8Pl5bPP41k+h5Zy8Zt7UkN+c09qyPCl\nhgxfasjwpYYMX2rI8KWGDF9qyPClhv4P5AnYl8B9j70AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f290b3c7fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(abs_loss[0,0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZPhSQ/8L63D1szyxln8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f290b719790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yinv = 1 - gt_class\n",
    "loss_neg = yinv*abs_loss\n",
    "select_mask = np.zeros(gt_class.shape)\n",
    "for num,i in enumerate(loss_neg):\n",
    "    # Getting the sorted indices loss in a flat array\n",
    "    indices = np.argsort(i,axis=None )\n",
    "\n",
    "    # Reshaping the flat indices to matrix indices\n",
    "    matrix_indices = np.unravel_index(indices,(abs_loss.shape[2], abs_loss.shape[3]))\n",
    "    matrix_indices_flipped = np.fliplr(matrix_indices)\n",
    "\n",
    "    num_positives = min(int(np.sum(gt_class[num,:,:])), yinv.sum())\n",
    "    print(num_positives)\n",
    "    # Taking the top num_positives indices only\n",
    "    matrix_indices_sorted = matrix_indices_flipped[:,0:num_positives]\n",
    "\n",
    "    select_mask[num,0,matrix_indices_sorted[0],matrix_indices_sorted[1]] = 1 # Setting the top negative indices to one\n",
    "    plt.imshow(select_mask[0,0,:,:])\n",
    "    plt.show()\n",
    "    #     select_mask[num,0,:,:] = select_mask[num,0,:,:] + gt_class[num,0,:,:] # Setting all positive indices to one\n",
    "        \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhgxfasjwpYYMX2rI8KWGDF9qyPClhv4P5AnYl8B9j70AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f290b1b0f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(abs_loss[0,0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-60-f96987c44c72>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-60-f96987c44c72>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    loss_neg = yinv*abs_loss\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "yinv = 1 - gt_class\n",
    "    \n",
    "    loss_neg = yinv*abs_loss\n",
    "\n",
    "    select_mask = np.zeros(gt_class.shape)\n",
    "\n",
    "    for num,i in enumerate(loss_neg):\n",
    "        # Getting the sorted indices loss in a flat array\n",
    "        indices = np.argsort(i,axis=None )[:n]\n",
    "\n",
    "        # Reshaping the flat indices to matrix indices\n",
    "        matrix_indices = np.unravel_index(indices,(abs_loss.shape[2], abs_loss.shape[3]))\n",
    "#         matrix_indices_flipped = np.fliplr(matrix_indices)\n",
    "\n",
    "        num_positives = int(np.sum(gt_class[num,:,:]))\n",
    "        \n",
    "        # Taking the top num_positives indices only\n",
    "        matrix_indices_sorted = matrix_indices_flipped[:,0:num_positives]\n",
    "\n",
    "        select_mask[num,0,matrix_indices_sorted[1],matrix_indices_sorted[1]] = 1 # Setting the top negative indices to one\n",
    "        select_mask[num,0,:,:] = select_mask[num,0,:,:] + gt_class[num,0,:,:] # Setting all positive indices to one\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 2393, 2394, ..., 1206, 1236, 3599])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0, 39, 39, ..., 20, 20, 59]), array([ 0, 53, 54, ...,  6, 36, 59]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59, 20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 19, 19, 19, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 18, 18, 19, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_indices_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59, 36,  6,  5,  4,  3,  2,  1,  0, 59, 58, 57, 56, 55, 54, 53, 52,\n",
       "       51, 50, 49, 48, 47, 46, 45, 44, 43, 42,  7,  8,  9, 23, 34, 33, 32,\n",
       "       31, 30, 29, 28, 27, 26, 25, 24, 22, 10, 21, 20, 19, 18, 17, 16, 15,\n",
       "       14, 13, 12, 11, 41, 40, 39, 58,  9,  8,  7,  6,  5,  4,  3,  2,  1,\n",
       "        0, 59, 57, 11, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 10, 12,\n",
       "       38, 26, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 25, 13, 24, 23])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_indices_sorted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59, 20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 19, 19, 19, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 18, 18, 19, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_indices_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 39 39 ..., 20 20 59]\n"
     ]
    }
   ],
   "source": [
    "matrix_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 53, 54, ...,  6, 36, 59])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch pawan_files\r\n",
      "Your branch is up-to-date with 'origin/pawan_files'.\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   DatasetTensorCreator.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   DenseBoxesFaceDetectionReplication2.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   dataset.py\u001b[m\r\n",
      "\t\u001b[31mmodified:   network.py\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\r\n",
      "\t\u001b[31mUntitled.ipynb\u001b[m\r\n",
      "\t\u001b[31mdataset.pyc\u001b[m\r\n",
      "\t\u001b[31mnetwork.pyc\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -am \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
